{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwRUIOTKyUvu5qh7i4VvPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshavkundra/Machine-learing/blob/main/assinment3_keshav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and Implement 5- fold cross validation for multiple linear regression\n",
        "(using least square error fit).\n",
        "Steps:\n",
        "a) Divide the dataset into input features (all columns except price) and output variable\n",
        "(price)\n",
        "b) Scale the values of input features.\n",
        "c) Divide input and output features into five folds.\n",
        "d) Run five iterations, in each iteration consider one-fold as test set and remaining\n",
        "four sets as training set. Find the beta (ð›½) matrix, predicted values, and R2_score\n",
        "for each iteration using least square error fit.\n",
        "e) Use the best value of (ð›½) matrix (for which R2_score is maximum), to train the\n",
        "regressor for 70% of data and test the performance for remaining 30% data"
      ],
      "metadata": {
        "id": "jMlopMRT3zHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data=pd.read_csv(\"USA_Housing.csv\")\n",
        "X=data.drop('Price',axis=1).values\n",
        "y=data['Price'].values.reshape(-1,1)\n",
        "X=StandardScaler().fit_transform(X)\n",
        "folds=np.array_split(np.arange(len(X)),5)\n",
        "best_r2=-1\n",
        "best_beta=None\n",
        "for i in range(5):\n",
        "    test_idx=folds[i]\n",
        "    train_idx=np.concatenate([folds[j] for j in range(5) if j!=i])\n",
        "    X_train,y_train=X[train_idx],y[train_idx]\n",
        "    X_test,y_test=X[test_idx],y[test_idx]\n",
        "    X_train_b=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
        "    X_test_b=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
        "    beta=np.linalg.inv(X_train_b.T@X_train_b)@X_train_b.T@y_train\n",
        "    y_pred=X_test_b@beta\n",
        "    r2=r2_score(y_test,y_pred)\n",
        "    if r2>best_r2:\n",
        "        best_r2=r2\n",
        "        best_beta=beta\n",
        "n=int(0.7*len(X))\n",
        "X_train,y_train=X[:n],y[:n]\n",
        "X_test,y_test=X[n:],y[n:]\n",
        "X_train_b=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
        "X_test_b=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
        "y_pred=X_test_b@best_beta\n",
        "print(\"Final Evaluation with best beta on 70/30 split\")\n",
        "print(\"R2 Score on test set:\",r2_score(y_test,y_pred))\n",
        "print(\"Best Beta Matrix:\\n\",best_beta.flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ0F76-C5wDv",
        "outputId": "3d3e7d3a-e58a-4a5e-aadc-7d74caf779df"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation with best beta on 70/30 split\n",
            "R2 Score on test set: 0.917786034446557\n",
            "Best Beta Matrix:\n",
            " [1.23144707e+06 2.29921558e+05 1.64523054e+05 1.19737507e+05\n",
            " 1.12425659e+03 1.51317802e+05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Concept of Validation set for Multiple Linear Regression (Gradient Descent\n",
        "Optimization)\n",
        "Consider the same dataset of Q1, rather than dividing the dataset into five folds, divide the\n",
        "dataset into training set (56%), validation set (14%), and test set (30%).\n",
        "Consider four different values of learning rate i.e. {0.001,0.01,0.1,1}. Compute the values of\n",
        "regression coefficients for each value of learning rate after 1000 iterations.\n",
        "For each set of regression coefficients, compute R2_score for validation and test set and find\n",
        "the best value of regression coefficients."
      ],
      "metadata": {
        "id": "uwiQsLV76EmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data=pd.read_csv(\"USA_Housing.csv\")\n",
        "X=data.drop('Price',axis=1).values\n",
        "y=data['Price'].values.reshape(-1,1)\n",
        "X=StandardScaler().fit_transform(X)\n",
        "n=len(X)\n",
        "train_end=int(0.56*n)\n",
        "val_end=int(0.7*n)\n",
        "X_train,y_train=X[:train_end],y[:train_end]\n",
        "X_val,y_val=X[train_end:val_end],y[train_end:val_end]\n",
        "X_test,y_test=X[val_end:],y[val_end:]\n",
        "X_train=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
        "X_val=np.c_[np.ones((X_val.shape[0],1)),X_val]\n",
        "X_test=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
        "lrates=[0.001,0.01,0.1,1]\n",
        "best_r2=-1\n",
        "best_beta=None\n",
        "for lr in lrates:\n",
        "    beta=np.zeros((X_train.shape[1],1))\n",
        "    for _ in range(1000):\n",
        "        grad=(X_train.T@(X_train@beta-y_train))/len(X_train)\n",
        "        beta=beta-lr*grad\n",
        "    r2_val=r2_score(y_val,X_val@beta)\n",
        "    r2_test=r2_score(y_test,X_test@beta)\n",
        "    print(\"Learning Rate:\",lr)\n",
        "    print(\"Validation R2:\",r2_val,\"Test R2:\",r2_test)\n",
        "    print(\"Beta:\",beta.flatten())\n",
        "    if r2_val>best_r2:\n",
        "        best_r2=r2_val\n",
        "        best_beta=beta\n",
        "print(\"Best Beta:\",best_beta.flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmYNV2yK6Jl9",
        "outputId": "9def4dc0-7346-4502-8f9f-f4b2d32ccc03"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.001\n",
            "Validation R2: -0.9353469873109577 Test R2: -0.8082308505816143\n",
            "Beta: [779956.15931298 148633.92656087 100071.44202261  73571.12255806\n",
            "  22428.72038852  91893.41958638]\n",
            "Learning Rate: 0.01\n",
            "Validation R2: 0.9150931093041854 Test R2: 0.9174823125262497\n",
            "Beta: [ 1.23240080e+06  2.31659714e+05  1.63606011e+05  1.18757266e+05\n",
            " -8.60666297e+00  1.50706774e+05]\n",
            "Learning Rate: 0.1\n",
            "Validation R2: 0.9151040123364315 Test R2: 0.917477081644098\n",
            "Beta: [ 1.23244775e+06  2.31682635e+05  1.63635272e+05  1.19025219e+05\n",
            " -2.74956842e+02  1.50705906e+05]\n",
            "Learning Rate: 1\n",
            "Validation R2: 0.9151040123364313 Test R2: 0.9174770816440981\n",
            "Beta: [ 1.23244775e+06  2.31682635e+05  1.63635272e+05  1.19025219e+05\n",
            " -2.74956842e+02  1.50705906e+05]\n",
            "Best Beta: [ 1.23244775e+06  2.31682635e+05  1.63635272e+05  1.19025219e+05\n",
            " -2.74956842e+02  1.50705906e+05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing and Multiple Linear Regression\n",
        "Download the dataset regarding Car Price Prediction from the following link:\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
        "1. Load the dataset with following column names [\"symboling\", \"normalized_losses\",\n",
        "\"make\", \"fuel_type\", \"aspiration\",\"num_doors\", \"body_style\", \"drive_wheels\",\n",
        "\"engine_location\", \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "\"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\", \"stroke\",\n",
        "\"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "and replace all ? values with NaN\n",
        "2. Replace all NaN values with central tendency imputation. Drop the rows with NaN\n",
        "values in price column\n",
        "3. There are 10 columns in the dataset with non-numeric values. Convert these values to\n",
        "numeric values using following scheme:\n",
        "(i) For â€œnum_doorsâ€ and â€œnum_cylindersâ€: convert words (number names) to figures\n",
        "for e.g., two to 2\n",
        "(ii) For \"body_style\", \"drive_wheels\": use dummy encoding scheme\n",
        "(iii) For â€œmakeâ€, â€œaspirationâ€, â€œengine_locationâ€,fuel_type: use label encoding\n",
        "scheme\n",
        "(iv) For fuel_system: replace values containing string pfi to 1 else all values to 0.\n",
        "(v) For engine_type: replace values containing string ohc to 1 else all values to 0.\n",
        "4. Divide the dataset into input features (all columns except price) and output variable\n",
        "(price). Scale all input features.\n",
        "5. Train a linear regressor on 70% of data (using inbuilt linear regression function of\n",
        "Python) and test its performance on remaining 30% of data.\n",
        "6. Reduce the dimensionality of the feature set using inbuilt PCA decomposition and then\n",
        "again train a linear regressor on 70% of reduced data (using inbuilt linear regression\n",
        "function of Python). Does it lead to any performance improvement on test set"
      ],
      "metadata": {
        "id": "2m7c7AHinyzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "cols=[\"symboling\",\"normalized_losses\",\"make\",\"fuel_type\",\"aspiration\",\"num_doors\",\"body_style\",\"drive_wheels\",\"engine_location\",\"wheel_base\",\"length\",\"width\",\"height\",\"curb_weight\",\"engine_type\",\"num_cylinders\",\"engine_size\",\"fuel_system\",\"bore\",\"stroke\",\"compression_ratio\",\"horsepower\",\"peak_rpm\",\"city_mpg\",\"highway_mpg\",\"price\"]\n",
        "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\",header=None,names=cols,na_values='?')\n",
        "cat=[\"make\",\"fuel_type\",\"aspiration\",\"num_doors\",\"body_style\",\"drive_wheels\",\"engine_location\",\"engine_type\",\"fuel_system\",\"num_cylinders\"]\n",
        "num=[c for c in cols if c not in cat+[\"price\"]]\n",
        "df[num]=df[num].apply(pd.to_numeric,errors='coerce')\n",
        "df=df.dropna(subset=[\"price\"])\n",
        "for c in num: df[c]=df[c].fillna(df[c].mean())\n",
        "for c in cat: df[c]=df[c].fillna(df[c].mode()[0])\n",
        "df[\"num_doors\"]=df[\"num_doors\"].map({\"two\":2,\"four\":4})\n",
        "df[\"num_cylinders\"]=df[\"num_cylinders\"].map({\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"eight\":8,\"twelve\":12})\n",
        "df[\"fuel_system\"]=df[\"fuel_system\"].astype(str).str.contains(\"pfi\").astype(int)\n",
        "df[\"engine_type\"]=df[\"engine_type\"].astype(str).str.contains(\"ohc\").astype(int)\n",
        "df[\"make\"]=pd.factorize(df[\"make\"])[0]\n",
        "df[\"aspiration\"]=pd.factorize(df[\"aspiration\"])[0]\n",
        "df[\"engine_location\"]=pd.factorize(df[\"engine_location\"])[0]\n",
        "df[\"fuel_type\"]=pd.factorize(df[\"fuel_type\"])[0]\n",
        "df=pd.get_dummies(df,columns=[\"body_style\",\"drive_wheels\"],drop_first=True)\n",
        "X=df.drop(\"price\",axis=1).values\n",
        "y=df[\"price\"].astype(float).values\n",
        "sc=StandardScaler()\n",
        "X=sc.fit_transform(X)\n",
        "n=len(X)\n",
        "ntr=int(0.7*n)\n",
        "Xtr,Xte=X[:ntr],X[ntr:]\n",
        "ytr,yte=y[:ntr],y[ntr:]\n",
        "lr=LinearRegression().fit(Xtr,ytr)\n",
        "yhat=lr.predict(Xte)\n",
        "print(\"R2 without PCA:\",r2_score(yte,yhat))\n",
        "\n",
        "print()\n",
        "\n",
        "pca=PCA(n_components=0.95)\n",
        "Xtr_p=pca.fit_transform(Xtr)\n",
        "Xte_p=pca.transform(Xte)\n",
        "lr_p=LinearRegression().fit(Xtr_p,ytr)\n",
        "yhat_p=lr_p.predict(Xte_p)\n",
        "print(\"R2 with PCA:\",r2_score(yte,yhat_p))\n",
        "print(\"Improved:\",r2_score(yte,yhat_p)>r2_score(yte,yhat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWxc2zB4n7Vb",
        "outputId": "94dddad3-f489-470b-c8a1-bb0c2a23f136"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 without PCA: 0.18961326980816962\n",
            "\n",
            "R2 with PCA: 0.3415833571426846\n",
            "Improved: True\n"
          ]
        }
      ]
    }
  ]
}